{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.5em;color:crimson;\">\n",
    "    <b>4) Modeling(Machine Learning)</b> \n",
    " </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(df,lst,rng) :\n",
    "    ''' inputs\n",
    "    df : the data frame that should be normal\n",
    "    lst : list of columns of df that should be normal\n",
    "    rng : the range of normalization \n",
    "    \n",
    "        output\n",
    "    df : normalized df_in  '''\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler(feature_range = rng)\n",
    "    df[lst] = scaler.fit_transform(df[lst])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogReg(x,y,test_size,stratify) :\n",
    "    ## Fist x and y split for train and test,then model is created and fit\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=test_size,random_state=0,stratify=stratify)\n",
    "    Model = LogisticRegression(solver='liblinear')\n",
    "    Model.fit(x_train,y_train.ravel())\n",
    "    ## report of model evaluation is printed\n",
    "    print('Accuracy of Logistic Regression Model: ' , np.round(metrics.accuracy_score(y_test,Model.predict(x_test)),3))\n",
    "    Evaluation(Model,x,y,x_train,y_train,x_test,y_test)\n",
    "    print('*'*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(x,y,test_size,model,stratify) : ## Nive Bayes have 4 algorithms,The function takes it as an argument.Â  \n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=test_size,random_state=0,stratify=stratify)\n",
    "    Model = model()\n",
    "    Model.fit(x_train,y_train.ravel())\n",
    "    print('Accuracy of Model: ' , np.round(metrics.accuracy_score(y_test,Model.predict(x_test)),3))\n",
    "    Evaluation(Model,x,y,x_train,y_train,x_test,y_test)\n",
    "    print('*'*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(x,y,test_size,k,stratify) :\n",
    "    ## The function takes k as argument, these lists stores scores of k iterations of running knn algorithms\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    best_k = 0\n",
    "    best_score = 0\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=test_size,random_state=0,stratify=stratify)\n",
    "    \n",
    "    for i in range (1,k+1) :\n",
    "        Model = KNeighborsClassifier(i)\n",
    "        Model.fit(x_train,y_train.ravel())\n",
    "        train_score.append(np.round(Model.score(x_train,y_train),3))\n",
    "        test_score.append(np.round(Model.score(x_test,y_test),3))\n",
    "        \n",
    "    best_k = test_score.index(max(test_score))+1\n",
    "    best_score = max(test_score)\n",
    "    Model = KNeighborsClassifier(best_k)\n",
    "    Model.fit(x_train,y_train.ravel())\n",
    "    \n",
    "    print('Model accuracy for k = %d : '%k , np.round(test_score,3))\n",
    "    print('The best result is for k = %d with accuracy = %s .'%(best_k,best_score))\n",
    "    Evaluation(Model,x,y,x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    plt.plot(range(1,k+1),train_score,color='darkblue',label='train_accuracy')\n",
    "    plt.plot(range(1,k+1),test_score,color='darkorange',label='test_accuracy')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(Model,x,y,x_train,y_train,x_test,y_test) :\n",
    "    cv_score = (cross_val_score(Model, x_train, y_train.ravel(), cv = StratifiedKFold(10), scoring='accuracy')).mean()\n",
    "    print('Train score : ',np.round(Model.score(x_train,y_train),3))\n",
    "    print('Average Cross Validation Score : ',np.round(cv_score,3))\n",
    "    print('jaccard_score : ',np.round(jaccard_score(y_test,Model.predict(x_test)),3))\n",
    "    print('precision_score : ',np.round(precision_score(y_test,Model.predict(x_test)),3))\n",
    "    print('recall_score : ',np.round(recall_score(y_test,Model.predict(x_test)),3))\n",
    "    print('f1_score : ',np.round(f1_score(y_test,Model.predict(x_test)),3))\n",
    "    print('Result of confusion matrix : ')\n",
    "    print(confusion_matrix(y_test,Model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1) Create and Evaluate Models on normalized data ( just 5 features ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### df normalization ######################\n",
    "df_Normal1 = df.copy()\n",
    "features1 = ['Age','Experience','Income','CCAvg','Mortgage']\n",
    "df_Normal1 = Normalization(df_Normal1,features1,(1,5))\n",
    "#################### x,y ##############################\n",
    "x = df_Normal1.drop('Personal Loan',axis=1)\n",
    "y = df_Normal1['Personal Loan'].values.reshape(-1,1)\n",
    "###########################################################\n",
    "## Logistic Regression\n",
    "LogReg(x,y,0.1,None)\n",
    "\n",
    "## NaiveBayes\n",
    "print('Result of Gaussian Model : ')\n",
    "NaiveBayes(x,y,0.1,GaussianNB,None)\n",
    "print('Result of Complement Model : ')\n",
    "NaiveBayes(x,y,0.1,ComplementNB,None)\n",
    "print('Result of Multinomial Model : ')\n",
    "NaiveBayes(x,y,0.1,MultinomialNB,None)\n",
    "print('Result of Bernoulli Model : ')\n",
    "NaiveBayes(x,y,0.1,BernoulliNB,None)\n",
    "\n",
    "## KNN\n",
    "print('Result of KNN Model : ')\n",
    "KNN(x,y,0.1,20,stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### x,y ##############################\n",
    "x = df_Normal1.drop('Personal Loan',axis=1)\n",
    "y = df_Normal1['Personal Loan'].values.reshape(-1,1)\n",
    "###########################################################\n",
    "## Logistic Regression\n",
    "LogReg(x,y,0.1,y)\n",
    "\n",
    "## NaiveBayes\n",
    "print('Result of Gaussian Model : ')\n",
    "NaiveBayes(x,y,0.1,GaussianNB,y)\n",
    "print('Result of Complement Model : ')\n",
    "NaiveBayes(x,y,0.1,ComplementNB,y)\n",
    "print('Result of Multinomial Model : ')\n",
    "NaiveBayes(x,y,0.1,MultinomialNB,y)\n",
    "print('Result of Bernoulli Model : ')\n",
    "NaiveBayes(x,y,0.1,BernoulliNB,y)\n",
    "\n",
    "## KNN\n",
    "print('Result of KNN Model : ')\n",
    "KNN(x,y,0.1,20,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3) create and evaluate 6 Models on normalized data ( all features ) with stratify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### df normalization ######################\n",
    "df_Normal2 = df.copy()\n",
    "features2 = ['Age','Experience','Income','Family',\n",
    "           'CCAvg','Education','Mortgage','Securities Account','CD Account','Online'\n",
    "           ,'CreditCard']\n",
    "df_Normal2 = Normalization(df_Normal2,features2,(1,5))\n",
    "#################### x,y ##############################\n",
    "x = df_Normal2.drop('Personal Loan',axis=1)\n",
    "y = df_Normal2['Personal Loan'].values.reshape(-1,1)\n",
    "###########################################################\n",
    "## Logistic Regression\n",
    "LogReg(x,y,0.1,y)\n",
    "\n",
    "## NaiveBayes\n",
    "print('Result of Gaussian Model : ')\n",
    "NaiveBayes(x,y,0.1,GaussianNB,y)\n",
    "print('Result of Complement Model : ')\n",
    "NaiveBayes(x,y,0.1,ComplementNB,y)\n",
    "print('Result of Multinomial Model : ')\n",
    "NaiveBayes(x,y,0.1,MultinomialNB,y)\n",
    "print('Result of Bernoulli Model : ')\n",
    "NaiveBayes(x,y,0.1,BernoulliNB,y)\n",
    "\n",
    "## KNN\n",
    "print('Result of KNN Model : ')\n",
    "KNN(x,y,0.1,20,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model\n",
    "## The best Model is KNN for this dataset with Accuracy = 0.974 and f1-score = 0.851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_Normal2.drop('Personal Loan',axis=1).values\n",
    "y = df_Normal2['Personal Loan'].values.reshape(-1,1)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=0,stratify=y)\n",
    "\n",
    "k = 1\n",
    "Model = KNeighborsClassifier(k)\n",
    "Model.fit(x_train,y_train.ravel())\n",
    "y_pred = Model.predict(x_test)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix(y_test,y_pred), display_labels = ['Not be granted loans', 'be granted loans'])\n",
    "cm_display.plot(ax=ax,colorbar=False, cmap='Purples')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert train data, test data and predicted data to data frame just for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(x_train,columns=['Age','Experience','Income','Family','CCAvg','Education','Mortgage',\n",
    "                                         'Securities Account','CD Account','Online','CreditCard'])\n",
    "df_train.insert(11,'Personal Loan',y_train)\n",
    "\n",
    "df_test = pd.DataFrame(x_test,columns=['Age','Experience','Income','Family','CCAvg','Education','Mortgage',\n",
    "                                         'Securities Account','CD Account','Online','CreditCard'])\n",
    "df_test.insert(11,'Personal Loan',y_test)\n",
    "\n",
    "df_pred = pd.DataFrame(x_test,columns=['Age','Experience','Income','Family','CCAvg','Education','Mortgage',\n",
    "                                         'Securities Account','CD Account','Online','CreditCard'])\n",
    "df_pred.insert(11,'Personal Loan',y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fig.suptitle(f'$\\\\mathbf{{{\"train\"}}}$ Data Vs $\\\\mathbf{{{\"predicted\"}}}$ Data',y=0.905)\n",
    "for i,feature in enumerate(['CCAvg','Mortgage']) :\n",
    "    plt.subplot(2,1,i+1)\n",
    "    sns.scatterplot(data=df_train, x=feature,y='Income',hue='Personal Loan')\n",
    "    sns.scatterplot(data=df_pred, x=feature,y='Income',hue='Personal Loan',palette = ['Green','Red'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 2\n",
    "colors = [['darkblue','orange'],['Green','red'],['purple','crimson']]\n",
    "\n",
    "for j,feature in enumerate(['CCAvg','Mortgage','Education']) :\n",
    "    plt.figure(figsize=(14,12))\n",
    "    plt.subplot(rows,cols,j*2+1)\n",
    "    sns.scatterplot(data=df_test, x=feature,y='Income',hue='Personal Loan',palette = colors[j])\n",
    "    plt.title(f'$\\\\mathbf{{{\"Actual\"}}}$ Data')\n",
    "    if j == 2 :\n",
    "        plt.legend([],[], frameon=False)\n",
    "    plt.subplot(rows,cols,j*2+2)\n",
    "    sns.scatterplot(data=df_pred, x=feature,y='Income',hue='Personal Loan',palette = colors[j])\n",
    "    plt.title(f'$\\\\mathbf{{{\"predicted\"}}}$ Data')\n",
    "    if j == 2 :\n",
    "        plt.legend([],[], frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_test, x='CCAvg', y='Income', z='CD Account',\n",
    "              color='Personal Loan')\n",
    "\n",
    "fig.update_layout(\n",
    " annotations=[\n",
    "        dict(\n",
    "            x=0.47,\n",
    "            y=0.78,\n",
    "            \n",
    "            text=\"Actual Value\",\n",
    "            textangle=0,\n",
    "            ax=-90,\n",
    "            ay=0,\n",
    "            font=dict(\n",
    "                color=\"red\",\n",
    "                size=14\n",
    "            ),\n",
    "            arrowcolor=\"red\",\n",
    "            arrowsize=3,\n",
    "            arrowwidth=1,\n",
    "            arrowhead=1),])\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = px.scatter_3d(df_pred, x='CCAvg', y='Income', z='CD Account',\n",
    "              color='Personal Loan')\n",
    "fig.update_layout(\n",
    " annotations=[\n",
    "        dict(\n",
    "            x=0.47,\n",
    "            y=0.78,\n",
    "            \n",
    "            text=\"Incorrect Predicted Value\",\n",
    "            textangle=0,\n",
    "            ax=-130,\n",
    "            ay=0,\n",
    "            font=dict(\n",
    "                color=\"red\",\n",
    "                size=14\n",
    "            ),\n",
    "            arrowcolor=\"red\",\n",
    "            arrowsize=3,\n",
    "            arrowwidth=1,\n",
    "            arrowhead=1),])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
